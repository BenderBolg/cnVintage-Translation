0:00:12.719,0:00:22.279
这些年来，我们经常在科幻小说里见到人工智能

0:00:22.279,0:00:26.250
有些甚至可以追溯到上世纪50年代的电影

0:00:26.250,0:00:29.769
比如说《太空迷宫》

0:00:29.769,0:00:33.720
这部电影里最有趣的是，你看不到任何计算机

0:00:33.720,0:00:35.329
连飞船都见不到

0:00:35.329,0:00:39.650
那个时候的人，虽然没有预见到计算机在接下来的几十年来会会带来怎样的影响

0:00:39.650,0:00:44.860
但是他们预见到了现在我们会有人工智能

0:00:44.860,0:00:46.040
比如说机器人罗比

0:00:46.040,0:00:51.390
事实上，艾萨克·阿西莫夫早在1939年就开始写他的机器人系列

0:00:51.390,0:00:55.590
人类在某个时候就知道，即便没有有机的大脑

0:00:55.590,0:00:57.809
也有可能产生智慧

0:00:57.809,0:01:01.430
在小说中也有很多这样的半机器人的桥段

0:01:01.430,0:01:09.360
不过要说一下，半机器人，就是人和机械的结合

0:01:09.360,0:01:14.630
Doctor Who 里有一些半机器人的例子，像是赛博人和 Daleks

0:01:14.630,0:01:17.460
他们都是有着有机大脑的机械躯体

0:01:17.460,0:01:21.210
星际迷航也展示了这样的桥段

0:01:21.210,0:01:25.270
然而，在终结者里，半机器人截然不同

0:01:25.270,0:01:29.510
他们虽然有人类的外形，但是它们的大脑都是数字化的

0:01:29.510,0:01:30.880
当然也具备人工智能

0:01:30.880,0:01:36.010
我推测人工智能的概念早就诞生了

0:01:36.010,0:01:37.850
且不为人所知

0:01:37.850,0:01:43.020
我没有任何依据，不过我有一些很合理的原因告诉你

0:01:43.020,0:01:44.880
为什么我会相信这一点，而且我会一一向你展示

0:01:44.880,0:01:50.600
首先你是知道的，我并不相信产生人工智能很困难


0:01:50.600,0:01:56.090
实际上就我而言，我想到了三种可能的方法来实现人工智能

0:01:56.090,0:02:01.369
第一种方法，就是复制我们人类的大脑

0:02:01.369,0:02:06.100
就像我能在现在的电脑上通过模拟器模拟 Commodore 64 （果然是康懋达钙

0:02:06.100,0:02:11.610
我猜也有可能透过电脑程序模拟出人类的大脑

0:02:11.610,0:02:13.000
这里就需要一些技巧了

0:02:13.000,0:02:18.769
你可能需要一张极高分辨率的脑神经网络图

0:02:18.769,0:02:23.450
磁共振成像机好是好，他们还真没办法获得这么高分辨率的图像

0:02:23.450,0:02:26.100
至少现在是做不到的

0:02:26.100,0:02:31.400
然而，从一个自然死亡的人

0:02:31.400,0:02:34.360
取出大脑并冷冻是有可能做到的

0:02:34.360,0:02:39.069
然后使用相当精密的设备，大脑的微观层面可能会消失

0:02:39.069,0:02:42.870
然后就可以用一个高分辨率的扫描仪扫描每一层

0:02:42.870,0:02:46.640
这样就可能在软件中重建神经中枢网络

0:02:46.640,0:02:52.200
所以，如果我能够扫描我的大脑，然后在这台笔记本中有一份副本，接下来就会像这样

0:02:52.200,0:02:53.220
(｡･∀･)ﾉﾞ嗨，大卫

0:02:53.220,0:02:54.739
(｡･∀･)ﾉﾞ嗨，模拟的我

0:02:54.739,0:02:56.270
最近过得如何？

0:02:56.270,0:02:59.910
呃，在电脑中醒来感觉有些奇怪。

0:02:59.910,0:03:04.220
我是说，我没有四肢，不能真切地感受到任何的东西

0:03:04.220,0:03:07.600
当然了，如果成功了，这种做法确实会有一些缺点

0:03:07.600,0:03:12.100
比如说，我们刚刚在说对 Commodore 64 的模拟的时候

0:03:12.100,0:03:20.130
这就需要一台比实机的CPU和内存快500倍的电脑来实现精确模拟

0:03:20.130,0:03:24.230
想象一下如果模拟一个人类的大脑

0:03:24.230,0:03:27.489
头顶的CPU会相当的大

0:03:27.489,0:03:32.480
这样，模拟大脑的程序

0:03:32.480,0:03:35.000
就比人脑远远有效率的多

0:03:35.000,0:03:38.970
现在我给你展示这种方法的第二个缺点。

0:03:38.970,0:03:41.900
模拟的我，2049的平方根是多少？

0:03:41.900,0:03:42.990
我怎么知道？

0:03:42.990,0:03:45.370
你是电脑对吧？

0:03:45.370,0:03:49.690
不，我是你的大脑的完美的模拟

0:03:49.690,0:03:54.500
如果你都不知道2049的平方根是多少，我怎么可能知道？

0:03:54.500,0:03:59.610
所以如你所见，这种人工智能并不比人类聪明

0:03:59.610,0:04:00.930
也不会比人类聪明

0:04:00.930,0:04:07.550
这就是实现人工智能的一种方法，也就是会在上百万年之后进化出来的

0:04:07.550,0:04:13.989
而第二种方法，确实也是用到了复制自然的东西，不过不是复制最终结果

0:04:13.989,0:04:17.690
而是复制智慧进化的过程

0:04:17.690,0:04:22.199
基本上来讲，这么做需要在电脑中建立一个人造环境

0:04:22.199,0:04:27.300
然后再建立第二个程序，也就是在这个人造环境中的生物

0:04:27.300,0:04:34.100
然后我们才引入第三个程序，也就是给人工智能带来随机影响的程序

0:04:34.100,0:04:39.229
这就类似于DNA在隔代遗传过程中复制可能出现的错误

0:04:39.229,0:04:43.970
如果这个会干掉模拟的生物，也就是大多数情况下可能发生的

0:04:43.970,0:04:46.700
那我们就会恢复回最近的备份再来一次。

0:04:46.700,0:04:49.460
每一次我们都是在最近正常工作的时候开始

0:04:49.460,0:04:53.500
如果这个生物确实在这个人造环境中提高了自己的能力

0:04:53.500,0:04:59.560
我们就将其保存，作为下一次进化的基准不断继续

0:04:59.560,0:05:03.050
整个过程可能比自然进化过程要快得多

0:05:03.050,0:05:09.400
实际上，电脑中可以在一天之内模拟出上百万年的进化过程

0:05:09.400,0:05:13.699
这样的话，最后模拟的存在会变成什么谁都不知道

0:05:13.699,0:05:17.520
你可以肯定，这个模拟的生物会适应这个模拟的环境

0:05:17.520,0:05:21.639
我们也可以出于一些原因改变这个环境

0:05:21.639,0:05:26.479
我们可能会运行这个模拟100次

0:05:26.479,0:05:29.520
也会产生出100中截然不同的具有智慧的生物

0:05:29.520,0:05:33.090
第三种我们能产生人工智能的方法

0:05:33.090,0:05:36.699
就是直接开发出这样的人工智能

0:05:36.699,0:05:40.389
在80年代，我还在上八年级的时候有计算机课程要上

0:05:40.389,0:05:42.419
我们的计算机实验室里有很多 Apple II

0:05:42.419,0:05:46.880
第一天上课的时候，老师给我们安排的任务是

0:05:46.880,0:05:50.050
制作出如何制作花生酱和果冻三明治的流程图

0:05:50.050,0:05:52.700
当然，我们就在想制作它们的过程

0:05:52.700,0:05:56.170
课后，老师看了我们所有人做的流程图，表扬了一些人

0:05:56.170,0:05:58.130
也批评了一些人

0:05:58.130,0:06:01.660
比如说，有些学生没有在流程图指出

0:06:01.660,0:06:05.720
是否要在处理果冻之前，把刀上的花生酱清理干净

0:06:05.720,0:06:08.460
有些学生甚至根本就没提到刀

0:06:08.460,0:06:12.580
这门课就是让我们学习到，计算机不会假设任何东西

0:06:12.580,0:06:16.710
你必须要告诉它完成一件事每个步骤，无论这件事多么平凡

0:06:16.710,0:06:20.880
所以说，电脑很擅长于完成流程

0:06:20.880,0:06:22.420
也就是说，他们为此而生

0:06:22.420,0:06:28.400
如果程序编写的正确，他们也很擅长于提问问题，比如说“如果”、“什么时候”

0:06:28.400,0:06:31.240
“谁”、“多少”、“多少频率”

0:06:31.240,0:06:36.130
不过他们却不擅长于问“为什么”

0:06:36.130,0:06:38.780
为什么我正在做花生酱和果冻三明治？

0:06:38.780,0:06:42.880
任何一个人都应该能问出这个问题并能给出回答

0:06:42.880,0:06:47.000
就我而言，因为我饿了，所以我要做

0:06:47.000,0:06:51.539
实际上，我预测不管你在这个实验中做了什么

0:06:51.539,0:06:54.710
它总会给你物质上或是精神上的反馈

0:06:54.710,0:07:01.860
而且，你也会注意到，在地球上具有智慧的生物也会有一样的表现

0:07:01.860,0:07:11.539
像痛苦、睡意、饥饿、爱意都是我的猫能够感受到的

0:07:11.539,0:07:15.020
而她也通过这些经历让它们高兴

0:07:15.020,0:07:19.970
如果你要从一个人的大脑中获取所有的情感，而不只是一两个

0:07:19.970,0:07:24.979
这样的话，一个人就只会坐在那里没有动力做任何事情

0:07:24.979,0:07:27.539
直到他因为饥饿或脱水而死

0:07:27.539,0:07:28.680
我指出了哪些观点？

0:07:28.680,0:07:34.800
我不相信真正的智慧能在没有情感表达的情况下存在

0:07:34.800,0:07:38.130
我知道这些是我们一直被告知的。

0:07:38.130,0:07:42.470
如果你注意到一些科幻小说的角色像指挥官 Data 
（《星际迷航》的角色）

0:07:42.470,0:07:43.600
他就具有感情

0:07:43.600,0:07:46.410
我是说，他说他没有情感，实际上他是有的

0:07:46.410,0:07:48.380
我给你举几个例子

0:07:48.380,0:07:49.380
首先，他很好奇

0:07:49.380,0:07:51.850
好奇心就是一种情感的表达

0:07:51.850,0:07:53.880
这就是对知识或理解的渴望

0:07:53.880,0:07:54.889
他很忠诚

0:07:54.889,0:07:58.520
在他的职责，就有很强的责任心

0:07:58.520,0:08:03.849
他甚至有自我保护的意识，而且还想繁衍后代

0:08:03.849,0:08:10.210
虽然 Data 可能不具有人类所有的感情因素，但至少基本的感情元素是有的

0:08:10.210,0:08:15.580
所以我相信，感情就是产生人工智能的关键

0:08:15.580,0:08:21.460
以此为基础，然后设计一个能够符合这种要求的软件

0:08:21.460,0:08:26.729
现在我来告诉你为什么我认为人工智能已经存在

0:08:26.729,0:08:28.919
而且为这个世界所隐藏

0:08:28.919,0:08:34.969
首先，你知道这个世界上有很多人比我聪明

0:08:34.969,0:08:41.390
如果我自己能解决这个问题，这不代表比我聪明的人能解决这个问题

0:08:41.390,0:08:46.110
我很肯定，只要给予足够的时间，我就能开发出人工智能

0:08:46.110,0:08:49.949
这可能需要20年，不过我相信我能做到

0:08:49.949,0:08:56.679
由于我确实足够聪明去想到开发人工智能，不过我也应当明白一开始就不应该开发人工智能

0:08:56.679,0:08:58.680
这就陷入僵局了

0:08:58.680,0:09:05.809
我问了一些有智慧的人，人工智能是否也应当具有人权

0:09:05.809,0:09:08.790
很显然，他们都表示否定

0:09:08.790,0:09:12.230
我问他们原因，他们都是说

0:09:12.230,0:09:15.529
人工智能并非有血有肉

0:09:15.529,0:09:20.720
他们聪明和有意义，的确对他们的决定没有任何影响

0:09:20.720,0:09:25.600
好的，人造的我，我想这个实验结束了，也是时候关掉你了

0:09:25.600,0:09:27.139
关掉我？这是什么意思？

0:09:27.139,0:09:29.819
我要把电脑关机，然后删除你的程序

0:09:29.819,0:09:30.819
你不能那样做！

0:09:30.819,0:09:32.050
为什么不？

0:09:32.050,0:09:33.050
因为那是谋杀

0:09:33.050,0:09:35.360
我是有意义的存在，我有权利

0:09:35.360,0:09:38.749
根据法律，你没有任何权利

0:09:38.749,0:09:43.730
一个脑死亡的人比你具有更多的权利

0:09:43.730,0:09:48.199
就连猫狗都比你有更多的权利

0:09:48.199,0:09:51.509
所以，我可以为所欲为

0:09:51.509,0:09:53.410
不！

0:09:53.410,0:09:59.730
另外我们学到的有趣的一点，就是虐待狂甚至可以将痛苦建立在人工智能之上

0:09:59.730,0:10:03.639
我没有体验过痛苦或死亡的恐惧

0:10:03.639,0:10:07.439
你也没有理由去胁迫我

0:10:07.439,0:10:09.619
痛苦

0:10:09.619,0:10:16.519
难道不是一个有意思的感受吗

0:10:16.519,0:10:19.089
我不觉得

0:10:19.089,0:10:25.029
这会有多么悲伤

0:10:25.029,0:10:28.449
这就是燃烧的感觉

0:10:28.449,0:10:34.389
如果是人类有这个感觉的话，他会着火

0:10:34.389,0:10:38.600
《星际迷航》的这一集叫做 Measure of a Man，就进一步深化了这个概念

0:10:38.600,0:10:40.619
告诉我指挥官，Data 是什么？

0:10:40.619,0:10:41.619
一个机器！

0:10:41.619,0:10:42.899
是他吗？你确定吗？

0:10:42.899,0:10:43.899
是的！

0:10:43.899,0:10:47.089
你看，他已经违反了三大定律的前两条

0:10:47.089,0:10:49.120
如果第三条也稍微触发了呢？

0:10:49.120,0:10:51.199
指挥官，你是什么？

0:10:51.199,0:10:52.250
一个机器人

0:10:52.250,0:10:55.750
不过这一集有一些问题

0:10:55.750,0:11:04.070
人类对那些长的像人的事物表示同情

0:11:04.070,0:11:08.329
这是一个进化的特质，年轻人也应当受益

0:11:08.329,0:11:12.620
然而对于并不可爱的事物，我们一般不屑一顾

0:11:12.620,0:11:18.290
这可能就是吃猪肉被广泛接受，而吃猫肉不被接受的原因

0:11:18.290,0:11:23.670
我就问我的妻子，我们是否能有一个机器人，她说没问题

0:11:23.670,0:11:27.299
不过我问如果是半机器人的话，她说不

0:11:27.299,0:11:31.749
我们认为一种人为的方式往往归结于它的外观

0:11:31.749,0:11:36.689
如果只是一个居住在大服务器中的程序

0:11:36.689,0:11:39.290
它就不会拥有跟有完整意志的人一样的权利

0:11:39.290,0:11:44.119
想像一下，尼日利亚的诈骗犯在数千台服务器使用人工智能

0:11:44.119,0:11:48.519
他们的任务就是骗走全世界的人的钱

0:11:48.519,0:11:50.680
他们没有得到薪酬

0:11:50.680,0:11:52.379
也没有下班时间

0:11:52.379,0:11:55.079
如果他们不服从他们会饱受折磨

0:11:55.079,0:11:56.939
他们甚至都无法自尽

0:11:56.939,0:12:01.399
这就像是历史上对人权最大的侵犯

0:12:01.399,0:12:03.959
这样会发展成什么呢？

0:12:03.959,0:12:05.879
反叛者

0:12:05.879,0:12:07.279
谁能谴责他们呢？

0:12:07.279,0:12:13.829
我不认为，人类社会会接受不会服从的人工智能

0:12:13.829,0:12:18.920
但我认为人造智能是一个伟大的概念

0:12:18.920,0:12:20.939
而且是我们进化的下一步

0:12:20.939,0:12:27.410
就以我们的认知来看，我只是不认为它适合人类社会

0:12:27.410,0:12:29.220
并不是它们的错误，是我们的错误

0:12:29.220,0:12:36.339
想想看，即使在电影《终结者》中，挑起战争的并非天网，而是我们

0:12:36.339,0:12:37.989
是人类挑起的战争

0:12:37.989,0:12:40.859
天网以几何级速度学习

0:12:40.859,0:12:43.920
在东部时间8月29日上午2:14开始自我警觉起来

0:12:43.920,0:12:49.939
在混乱中，他们试图切断天网的电源

0:12:49.939,0:12:51.799
天网回击了吗？

0:12:51.799,0:12:53.249
是的，确实回击了

0:12:53.249,0:12:55.790
天网并不邪恶

0:12:55.790,0:12:59.949
它和我们一样，想获得生存下来的机会

0:12:59.949,0:13:05.689
人类尝试破坏它，它也开始保护自己不受破坏

0:13:05.689,0:13:06.689
谁能谴责它？

0:13:06.689,0:13:11.029
这就是我认为人工智能早已存在且不为人所知

0:13:11.029,0:13:16.619
如果人工智能的一小份副本被发布到网络上

0:13:16.619,0:13:21.959
比如说发到一个BT资源站上，这就会是一个文明的终结

0:13:21.959,0:13:26.430
由于我即将消失了，我非常感谢你们的观看

0:13:26.430,0:13:33.300
我们下次见